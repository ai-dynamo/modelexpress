# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# TRT-LLM image with NIXL for P2P weight transfers
# Uses vLLM base (which has working UCX) + NIXL + TRT-LLM + ModelExpress
#
# Build: docker build -t modelexpress-trtllm-client:latest -f Dockerfile.trtllm .

FROM vllm/vllm-openai:v0.12.0

USER root

# Install NIXL (use version that works with pip install)
# Note: nixl>=0.8.0 has UCX plugin issues, 0.6.0 is known to work
RUN python3 -m pip install --no-cache-dir 'nixl[cu12]>=0.6.0,<0.8.0' || \
    python3 -m pip install --no-cache-dir 'nixl[cu12]'

# Install TensorRT-LLM
RUN pip install --quiet tensorrt-llm || echo "TRT-LLM install completed (may have warnings)"

# Install gRPC dependencies
RUN pip install --quiet grpcio grpcio-tools protobuf

# Copy and install ModelExpress client
COPY modelexpress_common/proto /opt/modelexpress/proto
COPY modelexpress_client/python/modelexpress /opt/modelexpress/client/modelexpress
COPY modelexpress_client/python/pyproject.toml /opt/modelexpress/client/

WORKDIR /opt/modelexpress/client
RUN python3 -m grpc_tools.protoc \
        -I/opt/modelexpress/proto \
        --python_out=/opt/modelexpress/client/modelexpress \
        --grpc_python_out=/opt/modelexpress/client/modelexpress \
        /opt/modelexpress/proto/p2p.proto && \
    sed -i 's/^import p2p_pb2/from . import p2p_pb2/' /opt/modelexpress/client/modelexpress/p2p_pb2_grpc.py

# Install ModelExpress without NIXL dependency (we installed it separately)
RUN pip uninstall -y modelexpress 2>/dev/null || true && \
    rm -rf /usr/local/lib/python3.12/dist-packages/modelexpress* && \
    pip install --no-deps .

# Verify NIXL works
RUN python3 -c "import nixl; print(f'NIXL OK')" || echo "NIXL import check"

# Import checks
WORKDIR /workspace
RUN python3 -c "from modelexpress.trtllm_loader import MxTrtllmSourcePublisher, MxTrtllmTargetLoader; print('ModelExpress TRT-LLM loaders: OK')"
